import os
import importlib
import inspect
import json
from typing import Dict, Optional, Any

from dotenv import load_dotenv
from openai import OpenAI

from memory import ConversationMemory
from mcp.protocol import MCPMessage
from mcp.interfaces import BaseTool
# å¯¼å…¥ RAGTool ä»¥ä¾¿ç‰¹æ®Šå¤„ç†
from tools.rag_tool import RAGTool

load_dotenv()

class SmartAgent:
    def __init__(self, agent_id="smart_agent_001", tools_package_path="tools"):
        self.agent_id = agent_id
        self.memory = ConversationMemory()

        provider = os.getenv("LLM_PROVIDER", "openai").lower() # é»˜è®¤ä¸º openaiï¼Œå¹¶è½¬ä¸ºå°å†™

        api_key = None
        base_url = None
        
        # æ ¹æ® provider çš„å€¼ï¼Œä» .env åŠ è½½å¯¹åº”çš„é…ç½®
        if provider == "openai":
            api_key = os.getenv("OPENAI_API_KEY")
            self.model_name = os.getenv("OPENAI_MODEL_NAME", "gpt-4o")
            # OpenAI å®˜æ–¹æœåŠ¡ä¸éœ€è¦ base_url
        
        elif provider == "deepseek":
            api_key = os.getenv("DEEPSEEK_API_KEY")
            self.model_name = os.getenv("DEEPSEEK_MODEL_NAME", "deepseek-chat")
            base_url = "https://api.deepseek.com" # DeepSeek çš„ URL æ˜¯å›ºå®šçš„
            
        elif provider == "custom":
            api_key = os.getenv("CUSTOM_LLM_API_KEY")
            self.model_name = os.getenv("CUSTOM_LLM_MODEL_NAME")
            base_url = os.getenv("CUSTOM_LLM_BASE_URL") # ç”¨æˆ·è‡ªå·±æä¾› URL
            if not base_url:
                raise ValueError("LLM_PROVIDER is 'custom', but CUSTOM_LLM_BASE_URL is not set!")
        
        else:
            raise ValueError(f"Unsupported LLM provider '{provider}'. Please check your .env file.")

        if not api_key:
            raise ValueError(f"API key for provider '{provider}' is not set in .env file.")
        
        # 3. ä½¿ç”¨åŠ è½½åˆ°çš„é…ç½®æ¥åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
        # æ— è®ºç”¨æˆ·é€‰æ‹©å“ªä¸ª providerï¼Œæˆ‘ä»¬æœ€ç»ˆéƒ½ç”¨åŒä¸€ä¸ª OpenAI å®¢æˆ·ç«¯å¯¹è±¡
        self.client = OpenAI(
            api_key=api_key,
            base_url=base_url # å¦‚æœæ˜¯ OpenAI å®˜æ–¹ï¼Œbase_url ä¼šæ˜¯ Noneï¼Œå®¢æˆ·ç«¯ä¼šè‡ªåŠ¨å¤„ç†
        )
        
        print(f"Agent '{self.agent_id}' is online, powered by '{provider}' with model '{self.model_name}'.")

        # self.tools ç°åœ¨åªåŒ…å«â€œå¯é€‰å·¥å…·â€
        self.tools: Dict[str, BaseTool] = {}
        # self.rag_tool æ˜¯ä¸€ä¸ªç‰¹æ®Šçš„ã€è‡ªåŠ¨è°ƒç”¨çš„å·¥å…·
        self.rag_tool: Optional[RAGTool] = None
        self._load_and_register_tools(tools_package_path)
        
        print(f"  - Automatic RAG tool loaded: {'Yes' if self.rag_tool else 'No'}")
        print(f"  - Selectable tools loaded: {list(self.tools.keys())}")


    def _load_and_register_tools(self, package_path: str):
        """åŠ è½½æ‰€æœ‰å·¥å…·ï¼Œå¹¶å¯¹ RAGTool è¿›è¡Œç‰¹æ®Šæ³¨å†Œã€‚"""
        # (åŠ è½½é€»è¾‘ä¸ä¹‹å‰ç›¸åŒ)
        if not os.path.exists(package_path): return
        for filename in os.listdir(package_path):
            if filename.endswith("_tool.py"):
                module_name = f"{package_path}.{filename[:-3]}"
                try:
                    module = importlib.import_module(module_name)
                    for _, obj in inspect.getmembers(module, inspect.isclass):
                        if issubclass(obj, BaseTool) and obj is not BaseTool:
                            tool_instance = obj()
                            # --- å…³é”®æ”¹åŠ¨ï¼šåˆ†ç¦» RAG å·¥å…· ---
                            if isinstance(tool_instance, RAGTool):
                                self.rag_tool = tool_instance
                            else:
                                self.tools[tool_instance.name] = tool_instance
                except Exception as e:
                    print(f"Error loading tool from {filename}: {e}")

    def _reason(self, goal: str, retrieved_context:str) -> Dict[str, Any]:
        """
        ReAct å¾ªç¯ä¸­çš„â€œæ€è€ƒâ€æ­¥éª¤ã€‚
        è¿™ä¸ªæ–¹æ³•å°†ä»£æ›¿æ—§çš„ _decide_next_stepã€‚
        """
        history = self.memory.format_for_prompt()
        tool_descriptions = [tool.get_mcp_description() for tool in self.tools.values()]
        tools_json_string = json.dumps(tool_descriptions, indent=2, ensure_ascii=False)

        system_prompt = f"""
        ä½ æ˜¯ä¸€ä¸ªè‡ªä¸»ä»£ç†ï¼Œä½ çš„ä»»åŠ¡æ˜¯å®Œæˆç”¨æˆ·çš„æœ€ç»ˆç›®æ ‡ã€‚
        ä½ ä¼šé€šè¿‡ä¸€ä¸ª "æ€è€ƒ -> è¡ŒåŠ¨ -> è§‚å¯Ÿ" çš„å¾ªç¯æ¥å·¥ä½œã€‚

        åœ¨æ¯ä¸€æ­¥ï¼Œä½ éƒ½éœ€è¦åˆ†æç”¨æˆ·çš„æœ€ç»ˆç›®æ ‡å’Œåˆ°ç›®å‰ä¸ºæ­¢çš„å†å²è®°å½•ï¼Œç„¶åå†³å®šä¸‹ä¸€æ­¥çš„è¡ŒåŠ¨ã€‚

        [æœ€ç»ˆç›®æ ‡]
        {goal}

        [å†å²è®°å½•]
        {history}

        [å¯ç”¨å·¥å…·]
        {tools_json_string}

        [èƒŒæ™¯ä¿¡æ¯]
        {retrieved_context if retrieved_context else "æ— ç›¸å…³èƒŒæ™¯ä¿¡æ¯ã€‚"}

        ä½ çš„è¾“å‡ºå¿…é¡»æ˜¯ä¸€ä¸ªä¸¥æ ¼çš„ JSON å¯¹è±¡ï¼Œæ ¼å¼å¦‚ä¸‹:
        {{
            "thought": "ä½ å¯¹å½“å‰æƒ…å†µçš„åˆ†æï¼Œä»¥åŠä¸‹ä¸€æ­¥è¡ŒåŠ¨çš„è®¡åˆ’ã€‚",
            "action": "ä¸‹ä¸€æ­¥è¦æ‰§è¡Œçš„å·¥å…·åç§°ã€‚å¦‚æœä»»åŠ¡å·²å®Œæˆï¼Œè¯·ä½¿ç”¨ 'finish'ã€‚",
            "action_input": {{
                "param1": "value1",
                ...
            }}
        }}

        - å¦‚æœä½ è®¤ä¸ºæœ€ç»ˆç›®æ ‡å·²ç»è¾¾æˆï¼Œè¯·å°† "action" å­—æ®µè®¾ç½®ä¸º "finish"ï¼Œå¹¶å¯ä»¥åœ¨ "thought" å­—æ®µä¸­æä¾›æœ€ç»ˆçš„æ€»ç»“æ€§å›ç­”ã€‚
        - å¦‚æœè¡ŒåŠ¨å¤±è´¥ï¼Œè¯·åˆ†æè§‚å¯Ÿåˆ°çš„é”™è¯¯ä¿¡æ¯ï¼Œå¹¶åœ¨ä¸‹ä¸€æ­¥æ€è€ƒä¸­å°è¯•ä¿®å¤å®ƒã€‚
        """
        
        # æ³¨æ„ï¼šè¿™é‡Œçš„ user_prompt ç•™ç©ºï¼Œå› ä¸ºæ‰€æœ‰ä¿¡æ¯éƒ½åœ¨ system_prompt é‡Œäº†
        user_prompt = "Please proceed with the next step." 
 
        response = self.client.chat.completions.create(
            model=self.model_name,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            response_format={"type": "json_object"}
        )
        decision = json.loads(response.choices[0].message.content)
        return decision
    
    def run(self, goal: str):
        """
        æ‰§è¡Œ ReAct å¾ªç¯æ¥å®Œæˆä¸€ä¸ªå¤æ‚çš„ç›®æ ‡ã€‚
        """
        self.memory.clear()
        self.memory.add_message("user", f"My goal is: {goal}")
        
        max_turns = 10 # è®¾ç½®ä¸€ä¸ªæœ€å¤§å¾ªç¯æ¬¡æ•°ï¼Œé˜²æ­¢æ— é™å¾ªç¯
        

        for i in range(max_turns):
            print(f"\n--- Turn {i+1}/{max_turns} ---")
            
            # 1. æ€è€ƒ (Reason)
            print("ğŸ¤” Thinking...")
            
            rag_result = self.rag_tool.execute(query=goal.data["query"]) 
            retrieved_context = rag_result.get("retrieved_context", "")

            # æŠŠ context ä½œä¸ºå‚æ•°ä¼ é€’ç»™ _reason
            decision = self._reason(goal, retrieved_context) 
            thought = decision.get("thought", "No thought provided.")
            action = decision.get("action")
            action_input = decision.get("action_input", {})
            print(f"Thought: {thought}")
            self.memory.add_message("assistant", f"Thought: {thought}")

            # 2. æ£€æŸ¥æ˜¯å¦å®Œæˆ
            if action == "finish":
                print("âœ… Task Finished.")
                self.memory.add_message("assistant", f"Final Answer: {thought}")
                return thought

            # 3. è¡ŒåŠ¨ (Act)
            if action in self.tools:
                print(f"ğŸ¬ Acting: Using tool '{action}' with input {action_input}")
                self.memory.add_message("assistant", f"Action: Using tool {action} with input {json.dumps(action_input)}")
                
                # 4. è§‚å¯Ÿ (Observe)
                tool_result = self.tools[action].execute(**action_input)
                observation = f"Tool {action} returned: {json.dumps(tool_result, ensure_ascii=False)}"
                print(f"ğŸ‘€ Observation: {observation}")
                self.memory.add_message("system", observation)
            else:
                observation = f"Error: Unknown action '{action}'. Available tools are: {list(self.tools.keys())}"
                print(f"ğŸ‘€ Observation: {observation}")
                self.memory.add_message("system", observation)

        print("âš ï¸ Reached max turns. Stopping.")
        return "The agent reached the maximum number of turns without finishing the task."